\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {chapter}{Declaration}{i}{section*.2}}
\@writefile{toc}{\contentsline {chapter}{Abstract}{ii}{section*.4}}
\@writefile{toc}{\contentsline {chapter}{Contents}{iii}{section*.6}}
\citation{cairns1998stochastic}
\citation{cairns1998stochastic}
\citation{Barone-Adesi}
\citation{Oreskes}
\citation{Oreskes}
\citation{Mongwe}
\citation{Honore}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Introduction}{1}{section.1.1}}
\citation{Teugels}
\citation{Hornik}
\citation{Hornik}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Problem Statement}{2}{section.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Research Objectives}{2}{section.1.3}}
\citation{Olden}
\citation{Mongwe}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Importance of the Study}{3}{section.1.4}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Research Design and Methodology}{3}{section.1.5}}
\citation{Werbos}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.1}Neural Networks}{4}{subsection.1.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Multilayer Perceptron}}{4}{figure.caption.7}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:neuralnetwork}{{1.1}{4}{Multilayer Perceptron}{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.2}Approximating the Calibration Function, $\mathbf  {C}$}{4}{subsection.1.5.2}}
\newlabel{subsection:neural_networks:approximating_the_calibration_function_C}{{1.5.2}{4}{Approximating the Calibration Function, $\mathbf {C}$}{subsection.1.5.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces The Proposed Calibration Scheme}}{5}{figure.caption.8}}
\newlabel{fig:calibrationschemediagram}{{1.2}{5}{The Proposed Calibration Scheme}{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.3}Model Evaluation}{5}{subsection.1.5.3}}
\citation{Nielsen}
\citation{Nielsen}
\citation{Mongwe}
\citation{Honore}
\citation{Xie}
\citation{Xie}
\citation{Yao}
\citation{Yao}
\citation{Samad}
\citation{Xie}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Literature Review}{7}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Calibration of Stochastic Processes}{7}{section.2.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Neural Networks in Modelling and Model Calibration}{7}{section.2.2}}
\citation{Giebel}
\citation{glorot2011deep}
\citation{glorot2011deep}
\citation{glorot2011deep}
\citation{DBLP:journals/corr/ClevertUH15}
\citation{DBLP:journals/corr/ClevertUH15}
\citation{cs231n}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Methodology}{9}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Artificial Neurons}{9}{section.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Activation Functions}{9}{subsection.3.1.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Convolutional Layer}{9}{section.3.2}}
\citation{Scherer2010}
\citation{Scherer2010}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Rectifier Activation Function, f(x)}}{10}{figure.caption.9}}
\newlabel{fig:relu}{{3.1}{10}{Rectifier Activation Function, f(x)}{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Exponential Linear Unit (ELU)}}{10}{figure.caption.9}}
\newlabel{fig:elu}{{3.2}{10}{Exponential Linear Unit (ELU)}{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces 1D Convolutional Layer}}{10}{figure.caption.10}}
\newlabel{fig:1dconvolution}{{3.3}{10}{1D Convolutional Layer}{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces 2D Convolution Layer}}{10}{figure.caption.11}}
\newlabel{fig:2dconvolution}{{3.4}{10}{2D Convolution Layer}{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Pooling}{11}{subsection.3.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces A $2x2$ maximum pooling operation.}}{11}{figure.caption.12}}
\newlabel{fig:max-poolingoperation}{{3.5}{11}{A $2x2$ maximum pooling operation}{figure.caption.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Performance Measurement}{11}{section.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Coefficient of Determination}{11}{subsection.3.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Average Absolute Percentage Error}{12}{subsection.3.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Mean Squared Error}{12}{subsection.3.3.3}}
\citation{Merton}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Simulation Study}{13}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}The Merton Jump Diffusion Stochastic Process}{13}{section.4.1}}
\newlabel{equation:merton_log_returns}{{4.3}{13}{The Merton Jump Diffusion Stochastic Process}{equation.4.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Simulation}{13}{subsection.4.1.1}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Fully Connected Feed-forward Neural Network}{14}{section.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Multiple Parameter Prediction Architecture}{14}{subsection.4.2.1}}
\newlabel{subsection:fully_connected_ff_nn:architecture}{{4.2.1}{14}{Multiple Parameter Prediction Architecture}{subsection.4.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Multiple Output Prediction ANN}}{14}{figure.caption.13}}
\newlabel{fig:multipleoutputcnn}{{4.1}{14}{Multiple Output Prediction ANN}{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}The Dataset}{14}{subsection.4.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Convolutional Neural Network}{14}{section.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Multiple Parameter Prediction Architecture}{14}{subsection.4.3.1}}
\newlabel{chap:ConvolutionalNeuralNetwork-section:MultipleParameterPredictionArchitecture}{{4.3.1}{14}{Multiple Parameter Prediction Architecture}{subsection.4.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Multiple Output Prediction CNN}}{14}{figure.caption.14}}
\newlabel{fig:multipleoutputcnn}{{4.2}{14}{Multiple Output Prediction CNN}{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces MSE values over the training process for the 8-Layer Convolutional Neural Network}}{15}{figure.caption.15}}
\newlabel{fig:covnetmomse}{{4.3}{15}{MSE values over the training process for the 8-Layer Convolutional Neural Network}{figure.caption.15}{}}
\newlabel{fig:covnetmor2}{{4.4a}{15}{}{figure.caption.18}{}}
\newlabel{fig:covnetmor22}{{4.4b}{15}{}{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces R-Squared values over the training process for the multiple parameter prediction convolutional architecture (ELU activation units).\relax }}{15}{figure.caption.16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Dedicated Single Parameter Prediction Architecture}{15}{subsection.4.3.2}}
\newlabel{chap:ConvolutionalNeuralNetwork-section:SingleParameterPredictionArchitecture}{{4.3.2}{15}{Dedicated Single Parameter Prediction Architecture}{subsection.4.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Dedicated Single Parameter Prediction CNN}}{16}{figure.caption.19}}
\newlabel{fig:singleparameterdedicatedcnn}{{4.5}{16}{Dedicated Single Parameter Prediction CNN}{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsubsection}{Lambda}{16}{subsubsection*.20}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces R-Squared values for the predictions of $\lambda $ over the training process for the single parameter prediction convolutional architecture (ELU activation units).}}{16}{figure.caption.21}}
\newlabel{fig:lambda-rsquared}{{4.6}{16}{R-Squared values for the predictions of $\lambda $ over the training process for the single parameter prediction convolutional architecture (ELU activation units)}{figure.caption.21}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Parameter Interactions}{16}{section.4.4}}
\@writefile{toc}{\contentsline {subsubsection}{Variations in $\mu $}{17}{subsubsection*.22}}
\newlabel{fig:sensitivity_test:multiple_output:varying_mu:lambda}{{4.7a}{17}{The $\lambda $ parameter estimate plotted against the actual parameter value, $\lambda = 0.02$, for different values of $\mu $.\relax }{figure.caption.25}{}}
\newlabel{fig:sensitivity_test:multiple_output:varying_mu:jumps_mu}{{4.7b}{17}{The $\hat {\mu }_{jumps}$ parameter estimate plotted against the actual parameter value, $\mu _{jumps} = 0.05$, for different values of $\mu $.\relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces The parameter estimates (with $68\%$ confidence interval) of $\mathaccentV {hat}002{\sigma }$, $\mathaccentV {hat}002{\lambda }$, $\mathaccentV {hat}002{\mu }_{jumps}$ and $\mathaccentV {hat}002{\sigma }_{jumps}$, plotted against their actual values ($\sigma = 0.1$, $\lambda = 0.02$, $\mu _{jumps} = 0.05$ and $\sigma _{jumps} = 0.07$), while varying the $\mu $ parameter in the range $\left (-1.0, 1.0\right )$.\relax }}{17}{figure.caption.23}}
\@writefile{lof}{\contentsline {subfigure}{\numberline {(a)}{\ignorespaces The $\lambda $ parameter estimate plotted against the actual parameter value, $\lambda = 0.02$, for different values of $\mu $.\relax }}{17}{figure.caption.25}}
\@writefile{lof}{\contentsline {subfigure}{\numberline {(b)}{\ignorespaces The $\mathaccentV {hat}002{\mu }_{jumps}$ parameter estimate plotted against the actual parameter value, $\mu _{jumps} = 0.05$, for different values of $\mu $.\relax }}{17}{figure.caption.25}}
\newlabel{fig:sensitivity_test:multiple_output:varying_mu}{{4.7}{17}{The parameter estimates (with $68\%$ confidence interval) of $\hat {\sigma }$, $\hat {\lambda }$, $\hat {\mu }_{jumps}$ and $\hat {\sigma }_{jumps}$, plotted against their actual values ($\sigma = 0.1$, $\lambda = 0.02$, $\mu _{jumps} = 0.05$ and $\sigma _{jumps} = 0.07$), while varying the $\mu $ parameter in the range $\left (-1.0, 1.0\right )$.\relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsubsection}{Variations in $\sigma $}{17}{subsubsection*.26}}
\@writefile{toc}{\contentsline {subsubsection}{Variations in $\lambda $}{17}{subsubsection*.31}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces The deviation (with $68\%$ confidence interval) of the $\mathaccentV {hat}002{\sigma }$ parameter estimate from the actual parameter value, $\sigma $, for different values of $\sigma $. All the other parameters are kept constant as $\mu = 0.05, \lambda = 0.02, \mu _{jumps} = 0.05$ and $\sigma _{jumps} = 0.07$.\relax }}{18}{figure.caption.27}}
\newlabel{fig:sensitivity_test:multiple_output:varying_sigma:sigma}{{4.8}{18}{The deviation (with $68\%$ confidence interval) of the $\hat {\sigma }$ parameter estimate from the actual parameter value, $\sigma $, for different values of $\sigma $. All the other parameters are kept constant as $\mu = 0.05, \lambda = 0.02, \mu _{jumps} = 0.05$ and $\sigma _{jumps} = 0.07$.\relax }{figure.caption.27}{}}
\newlabel{fig:sensitivity_test:multiple_output:varying_sigma:mu}{{4.9a}{18}{The mean $\hat {\mu }$ parameter estimate plotted against the actual parameter value, $\mu = 0.05$, for different values of $\sigma $.\relax }{figure.caption.30}{}}
\newlabel{fig:sensitivity_test:multiple_output:varying_sigma:lambda}{{4.9b}{18}{The mean $\lambda $ parameter estimate plotted against the actual parameter value, $\lambda = 0.02$, for different values of $\sigma $.\relax }{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces The mean parameter estimates (with $68\%$ confidence interval) of $\mathaccentV {hat}002{\mu }$, $\mathaccentV {hat}002{\lambda }$, $\mathaccentV {hat}002{\mu }_{jumps}$ and $\mathaccentV {hat}002{\sigma }_{jumps}$, plotted against their actual values ($\mu = 0.05$, $\lambda = 0.02$, $\mu _{jumps} = 0.05$ and $\sigma _{jumps} = 0.07$), while varying the $\sigma $ parameter in the range $\left (0, 0.2\right )$.\relax }}{18}{figure.caption.28}}
\@writefile{lof}{\contentsline {subfigure}{\numberline {(a)}{\ignorespaces The mean $\mathaccentV {hat}002{\mu }$ parameter estimate plotted against the actual parameter value, $\mu = 0.05$, for different values of $\sigma $.\relax }}{18}{figure.caption.30}}
\@writefile{lof}{\contentsline {subfigure}{\numberline {(b)}{\ignorespaces The mean $\lambda $ parameter estimate plotted against the actual parameter value, $\lambda = 0.02$, for different values of $\sigma $.\relax }}{18}{figure.caption.30}}
\newlabel{fig:sensitivity_test:multiple_output:varying_sigma}{{4.9}{18}{The mean parameter estimates (with $68\%$ confidence interval) of $\hat {\mu }$, $\hat {\lambda }$, $\hat {\mu }_{jumps}$ and $\hat {\sigma }_{jumps}$, plotted against their actual values ($\mu = 0.05$, $\lambda = 0.02$, $\mu _{jumps} = 0.05$ and $\sigma _{jumps} = 0.07$), while varying the $\sigma $ parameter in the range $\left (0, 0.2\right )$.\relax }{figure.caption.28}{}}
\@writefile{toc}{\contentsline {subsubsection}{Variations in $\sigma _{jumps}$}{18}{subsubsection*.36}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces The mean deviation (with $68\%$ confidence interval) of the $\mathaccentV {hat}002{\lambda }$ parameter estimate from the actual parameter value, $\lambda $, for different values of $\lambda $. All the other parameters are kept constant as $\mu = 0.05, \sigma = 0.1, \mu _{jumps} = 0.05$ and $\sigma _{jumps} = 0.07$.\relax }}{19}{figure.caption.32}}
\newlabel{fig:sensitivity_test:multiple_output:varying_lambda:lambda}{{4.10}{19}{The mean deviation (with $68\%$ confidence interval) of the $\hat {\lambda }$ parameter estimate from the actual parameter value, $\lambda $, for different values of $\lambda $. All the other parameters are kept constant as $\mu = 0.05, \sigma = 0.1, \mu _{jumps} = 0.05$ and $\sigma _{jumps} = 0.07$.\relax }{figure.caption.32}{}}
\newlabel{fig:sensitivity_test:multiple_output:varying_lambda:jumps_sigma}{{4.11a}{19}{The mean $\hat {\sigma }_{jumps}$ parameter estimate plotted against the actual parameter value, $\sigma _{jumps} = 0.07$, for different values of $\lambda $.\relax }{figure.caption.35}{}}
\newlabel{fig:sensitivity_test:multiple_output:varying_lambda:jumps_mu}{{4.11b}{19}{The mean $\hat {\mu }_{jumps}$ parameter estimate plotted against the actual parameter value, $\mu _{jumps} = 0.05$, for different values of $\lambda $.\relax }{figure.caption.35}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces The mean parameter estimates (with $68\%$ confidence interval) of $\mathaccentV {hat}002{\mu }$, $\mathaccentV {hat}002{\sigma }$, $\mathaccentV {hat}002{\mu }_{jumps}$ and $\mathaccentV {hat}002{\sigma }_{jumps}$, plotted against their actual values ($\mu = 0.05$, $\sigma = 0.1$, $\mu _{jumps} = 0.05$ and $\sigma _{jumps} = 0.07$), while varying the $\lambda $ parameter in the range $\left (0, 0.025\right )$.\relax }}{19}{figure.caption.33}}
\@writefile{lof}{\contentsline {subfigure}{\numberline {(a)}{\ignorespaces The mean $\mathaccentV {hat}002{\sigma }_{jumps}$ parameter estimate plotted against the actual parameter value, $\sigma _{jumps} = 0.07$, for different values of $\lambda $.\relax }}{19}{figure.caption.35}}
\@writefile{lof}{\contentsline {subfigure}{\numberline {(b)}{\ignorespaces The mean $\mathaccentV {hat}002{\mu }_{jumps}$ parameter estimate plotted against the actual parameter value, $\mu _{jumps} = 0.05$, for different values of $\lambda $.\relax }}{19}{figure.caption.35}}
\newlabel{fig:sensitivity_test:multiple_output:varying_lambda}{{4.11}{19}{The mean parameter estimates (with $68\%$ confidence interval) of $\hat {\mu }$, $\hat {\sigma }$, $\hat {\mu }_{jumps}$ and $\hat {\sigma }_{jumps}$, plotted against their actual values ($\mu = 0.05$, $\sigma = 0.1$, $\mu _{jumps} = 0.05$ and $\sigma _{jumps} = 0.07$), while varying the $\lambda $ parameter in the range $\left (0, 0.025\right )$.\relax }{figure.caption.33}{}}
\@writefile{toc}{\contentsline {subsubsection}{Variations in $\mu _{jumps}$}{19}{subsubsection*.40}}
\newlabel{fig:sensitivity_test:multiple_output:varying_jumps_sigma:jumps_mu}{{4.12a}{20}{The mean $\hat {\mu }_{jumps}$ parameter estimate plotted against the actual parameter value, $\mu _{jumps} = 0.05$, for different values of $\mu _{jumps}$.\relax }{figure.caption.39}{}}
\newlabel{fig:sensitivity_test:multiple_output:varying_jumps_sigma:lambda}{{4.12b}{20}{The mean $\lambda $ parameter estimate plotted against the actual parameter value, $\lambda = 0.2$, for different values of $\sigma _{jumps}$.\relax }{figure.caption.39}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces The mean parameter estimates (with $68\%$ confidence interval) of $\mathaccentV {hat}002{\mu }$, $\mathaccentV {hat}002{\sigma }$, $\mathaccentV {hat}002{\mu }_{jumps}$ and $\lambda $, plotted against their actual values ($\mu = 0.05$, $\sigma = 0.1$, $\mu _{jumps} = 0.05$ and $\lambda = 0.02$), while varying the $\sigma _{jumps}$ parameter in the range $\left (0, 0.2\right )$.\relax }}{20}{figure.caption.37}}
\@writefile{lof}{\contentsline {subfigure}{\numberline {(a)}{\ignorespaces The mean $\mathaccentV {hat}002{\mu }_{jumps}$ parameter estimate plotted against the actual parameter value, $\mu _{jumps} = 0.05$, for different values of $\mu _{jumps}$.\relax }}{20}{figure.caption.39}}
\@writefile{lof}{\contentsline {subfigure}{\numberline {(b)}{\ignorespaces The mean $\lambda $ parameter estimate plotted against the actual parameter value, $\lambda = 0.2$, for different values of $\sigma _{jumps}$.\relax }}{20}{figure.caption.39}}
\newlabel{fig:sensitivity_test:multiple_output:varying_jumps_sigma}{{4.12}{20}{The mean parameter estimates (with $68\%$ confidence interval) of $\hat {\mu }$, $\hat {\sigma }$, $\hat {\mu }_{jumps}$ and $\lambda $, plotted against their actual values ($\mu = 0.05$, $\sigma = 0.1$, $\mu _{jumps} = 0.05$ and $\lambda = 0.02$), while varying the $\sigma _{jumps}$ parameter in the range $\left (0, 0.2\right )$.\relax }{figure.caption.37}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.13}{\ignorespaces The mean deviation (with $68\%$ confidence interval) of the $\mathaccentV {hat}002{\mu }_{jumps}$ parameter estimate from the actual parameter value, $\mu _{jumps}$, for different values of $\mu _{jumps}$. All the other parameters are kept constant as $\mu = 0.05, \sigma = 0.1, \lambda = 0.02$ and $\sigma _{jumps} = 0.07$.\relax }}{20}{figure.caption.41}}
\newlabel{fig:sensitivity_test:multiple_output:varying_jumps_mu:jumps_mu}{{4.13}{20}{The mean deviation (with $68\%$ confidence interval) of the $\hat {\mu }_{jumps}$ parameter estimate from the actual parameter value, $\mu _{jumps}$, for different values of $\mu _{jumps}$. All the other parameters are kept constant as $\mu = 0.05, \sigma = 0.1, \lambda = 0.02$ and $\sigma _{jumps} = 0.07$.\relax }{figure.caption.41}{}}
\newlabel{fig:sensitivity_test:multiple_output:varying_jumps_mu:mu}{{4.14a}{21}{The mean $\hat {\mu }$ parameter estimate plotted against the actual parameter value, $\mu = 0.05$, for different values of $\mu _{jumps}$.\relax }{figure.caption.45}{}}
\newlabel{fig:sensitivity_test:multiple_output:varying_jumps_mu:sigma}{{4.14b}{21}{The mean $\sigma $ parameter estimate plotted against the actual parameter value, $\sigma = 0.1$, for different values of $\mu _{jumps}$.\relax }{figure.caption.45}{}}
\newlabel{fig:sensitivity_test:multiple_output:varying_jumps_mu:jumps_sigma}{{4.14c}{21}{The mean $\hat {\sigma }_{jumps}$ parameter estimate plotted against the actual parameter value, $\sigma _{jumps} = 0.07$, for different values of $\mu _{jumps}$.\relax }{figure.caption.46}{}}
\newlabel{fig:sensitivity_test:multiple_output:varying_jumps_mu:lambda}{{4.14d}{21}{The mean $\lambda $ parameter estimate plotted against the actual parameter value, $\lambda = 0.2$, for different values of $\mu _{jumps}$.\relax }{figure.caption.46}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.14}{\ignorespaces The mean parameter estimates (with $68\%$ confidence interval) of $\mathaccentV {hat}002{\mu }$, $\mathaccentV {hat}002{\sigma }$, $\mathaccentV {hat}002{\sigma }_{jumps}$ and $\lambda $, plotted against their actual values ($\mu = 0.05$, $\sigma = 0.1$, $\lambda = 0.02$ and $\sigma _{jumps} = 0.07$), while varying the $\mu _{jumps}$ parameter in the range $\left (-0.5, 0.5\right )$.\relax }}{21}{figure.caption.42}}
\@writefile{lof}{\contentsline {subfigure}{\numberline {(a)}{\ignorespaces The mean $\mathaccentV {hat}002{\mu }$ parameter estimate plotted against the actual parameter value, $\mu = 0.05$, for different values of $\mu _{jumps}$.\relax }}{21}{figure.caption.45}}
\@writefile{lof}{\contentsline {subfigure}{\numberline {(b)}{\ignorespaces The mean $\sigma $ parameter estimate plotted against the actual parameter value, $\sigma = 0.1$, for different values of $\mu _{jumps}$.\relax }}{21}{figure.caption.45}}
\@writefile{lof}{\contentsline {subfigure}{\numberline {(c)}{\ignorespaces The mean $\mathaccentV {hat}002{\sigma }_{jumps}$ parameter estimate plotted against the actual parameter value, $\sigma _{jumps} = 0.07$, for different values of $\mu _{jumps}$.\relax }}{21}{figure.caption.46}}
\@writefile{lof}{\contentsline {subfigure}{\numberline {(d)}{\ignorespaces The mean $\lambda $ parameter estimate plotted against the actual parameter value, $\lambda = 0.2$, for different values of $\mu _{jumps}$.\relax }}{21}{figure.caption.46}}
\newlabel{fig:sensitivity_test:multiple_output:varying_jumps_mu}{{4.14}{21}{The mean parameter estimates (with $68\%$ confidence interval) of $\hat {\mu }$, $\hat {\sigma }$, $\hat {\sigma }_{jumps}$ and $\lambda $, plotted against their actual values ($\mu = 0.05$, $\sigma = 0.1$, $\lambda = 0.02$ and $\sigma _{jumps} = 0.07$), while varying the $\mu _{jumps}$ parameter in the range $\left (-0.5, 0.5\right )$.\relax }{figure.caption.42}{}}
\bibstyle{ussagus}
\bibdata{export}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Results}{22}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:results}{{5}{22}{Results}{chapter.5}{}}
\newlabel{fig:convolutional-architecture---multiple-output---elumu}{{5.1a}{22}{Convolutional Architecture - Multiple Output - ELU}{figure.caption.49}{}}
\newlabel{fig:fully-connected-architecture---multiple-output---elumu}{{5.1b}{22}{Fully Connected Architecture - Multiple Output - EL}{figure.caption.49}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Various model distributions of the predicted values of $\mu $ with true value $0,05$.\relax }}{22}{figure.caption.47}}
\@writefile{lof}{\contentsline {subfigure}{\numberline {(a)}{\ignorespaces Convolutional Architecture - Multiple Output - ELU}}{22}{figure.caption.49}}
\@writefile{lof}{\contentsline {subfigure}{\numberline {(b)}{\ignorespaces Fully Connected Architecture - Multiple Output - EL}}{22}{figure.caption.49}}
\newlabel{fig:individual-parameter-estimation-results--mu}{{5.1}{22}{Various model distributions of the predicted values of $\mu $ with true value $0,05$.\relax }{figure.caption.47}{}}
\newlabel{fig:convolutional-architecture---multiple-output---elusigma}{{5.2a}{22}{Convolutional Architecture - Multiple Output - ELU}{figure.caption.52}{}}
\newlabel{fig:fully-connected-architecture---multiple-output---elusigma}{{5.2b}{22}{Fully Connected Architecture - Multiple Output - EL}{figure.caption.52}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Various model distributions of the predicted values of $\sigma $ with true value $0,1$.\relax }}{22}{figure.caption.50}}
\@writefile{lof}{\contentsline {subfigure}{\numberline {(a)}{\ignorespaces Convolutional Architecture - Multiple Output - ELU}}{22}{figure.caption.52}}
\@writefile{lof}{\contentsline {subfigure}{\numberline {(b)}{\ignorespaces Fully Connected Architecture - Multiple Output - EL}}{22}{figure.caption.52}}
\newlabel{fig:individual-parameter-estimation-results--sigma}{{5.2}{22}{Various model distributions of the predicted values of $\sigma $ with true value $0,1$.\relax }{figure.caption.50}{}}
\newlabel{fig:convolutional-architecture---multiple-output---elulambda}{{5.3a}{23}{Convolutional Architecture - Multiple Output - ELU}{figure.caption.56}{}}
\newlabel{fig:fully-connected-architecture---multiple-output---elulambda}{{5.3b}{23}{Fully Connected Architecture - Multiple Output - EL}{figure.caption.56}{}}
\newlabel{fig:convolutional-architecture---single-output---elulambda}{{5.3c}{23}{Convolutional Architecture - Single Output - ELU}{figure.caption.57}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Various model distributions of the predicted values of $\lambda $ with true value $0,02$.\relax }}{23}{figure.caption.53}}
\@writefile{lof}{\contentsline {subfigure}{\numberline {(a)}{\ignorespaces Convolutional Architecture - Multiple Output - ELU}}{23}{figure.caption.56}}
\@writefile{lof}{\contentsline {subfigure}{\numberline {(b)}{\ignorespaces Fully Connected Architecture - Multiple Output - EL}}{23}{figure.caption.56}}
\@writefile{lof}{\contentsline {subfigure}{\numberline {(c)}{\ignorespaces Convolutional Architecture - Single Output - ELU}}{23}{figure.caption.57}}
\newlabel{fig:individual-parameter-estimation-results--lambda}{{5.3}{23}{Various model distributions of the predicted values of $\lambda $ with true value $0,02$.\relax }{figure.caption.53}{}}
\newlabel{fig:convolutional-architecture---multiple-output---elujumps-mu}{{5.4a}{24}{Convolutional Architecture - Multiple Output - ELU}{figure.caption.60}{}}
\newlabel{fig:fully-connected-architecture---multiple-output---elujumps-mu}{{5.4b}{24}{Fully Connected Architecture - Multiple Output - EL}{figure.caption.60}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Various model distributions of the predicted values of $\mu _{jumps}$ with true value $0,05$.\relax }}{24}{figure.caption.58}}
\@writefile{lof}{\contentsline {subfigure}{\numberline {(a)}{\ignorespaces Convolutional Architecture - Multiple Output - ELU}}{24}{figure.caption.60}}
\@writefile{lof}{\contentsline {subfigure}{\numberline {(b)}{\ignorespaces Fully Connected Architecture - Multiple Output - EL}}{24}{figure.caption.60}}
\newlabel{fig:individual-parameter-estimation-results--mu_jumps}{{5.4}{24}{Various model distributions of the predicted values of $\mu _{jumps}$ with true value $0,05$.\relax }{figure.caption.58}{}}
\bibcite{cs231n}{{1}{}{{cs2}}{{}}}
\bibcite{Barone-Adesi}{{2}{2015}{{Barone-Adesi}}{{}}}
\bibcite{cairns1998stochastic}{{3}{1998}{{Cairns \textit  {et~al.{}}}}{{Cairns, Dickson, Macdonald, Waters \BIBand {} Willder}}}
\bibcite{DBLP:journals/corr/ClevertUH15}{{4}{2015}{{Clevert \textit  {et~al.{}}}}{{Clevert, Unterthiner \BIBand {} Hochreiter}}}
\bibcite{Giebel}{{5}{2013}{{Giebel \BIBand {} Rainer}}{{}}}
\bibcite{glorot2011deep}{{6}{2011}{{Glorot \textit  {et~al.{}}}}{{Glorot, Bordes \BIBand {} Bengio}}}
\bibcite{Honore}{{7}{1998}{{Honore}}{{}}}
\bibcite{Hornik}{{8}{1989}{{Hornik \textit  {et~al.{}}}}{{Hornik, Stinchcombe \BIBand {} White}}}
\bibcite{Merton}{{9}{1976}{{Merton}}{{}}}
\bibcite{Mongwe}{{10}{2015}{{Mongwe}}{{}}}
\bibcite{Nielsen}{{11}{2000}{{Nielsen \textit  {et~al.{}}}}{{Nielsen, Madsen \BIBand {} Young}}}
\bibcite{Olden}{{12}{2002}{{Olden \BIBand {} Jackson}}{{}}}
\bibcite{Oreskes}{{13}{1994}{{Oreskes \textit  {et~al.{}}}}{{Oreskes, Shrader-Frechette \BIBand {} Belitz}}}
\bibcite{Samad}{{14}{1992}{{Samad \BIBand {} Mathur}}{{}}}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{25}{section*.62}}
\bibcite{Scherer2010}{{15}{2010}{{Scherer \textit  {et~al.{}}}}{{Scherer, M{\"u}ller \BIBand {} Behnke}}}
\bibcite{Teugels}{{16}{2004}{{Teugels \BIBand {} Sundt}}{{}}}
\bibcite{Werbos}{{17}{1990}{{Werbos}}{{}}}
\bibcite{Xie}{{18}{2007}{{Xie \textit  {et~al.{}}}}{{Xie, Kulasiri, Samarasinghe \BIBand {} Rajanayaka}}}
\bibcite{Yao}{{19}{2000}{{Yao \textit  {et~al.{}}}}{{Yao, Li \BIBand {} Tan}}}
